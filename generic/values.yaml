# Default values for liminal-manual.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- The type of workload to deploy. Can be 'deployment' or 'statefulset'.
type: deployment

# -- Replica count
replicaCount: 1

image:
  # -- The image repository
  repository: nginx
  # -- The image pull policy
  pullPolicy: IfNotPresent
  # -- Overrides the image tag whose default is the chart appVersion.
  tag: ""

# -- The secrets used to pull the image
imagePullSecrets: []
# -- The release name override
nameOverride: ""
# -- The full release name override
fullnameOverride: ""

serviceAccount:
  # -- Specifies whether a service account should be created
  create: true
  # -- Automatically mount a ServiceAccount's API credentials?
  automount: true
  # -- Annotations to add to the service account
  annotations: {}
  # -- The name of the service account to use.
  name: ""

# -- Annotations to add to deployments
deploymentAnnotations: {}
# -- Annotations to add to the pods
podAnnotations: {}
# -- Label to add to the pods
podLabels: {}

# -- The Pod Security Context
podSecurityContext: {}
  # fsGroup: 2000

# -- The Security Context
securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  # -- The service type
  type: ClusterIP
  # -- The service port
  port: 80

  sessionAffinity:
    # -- Whether to enable session affinity
    enabled: false
    # -- The session affinity type
    type: ClientIP
    # -- The session affinity timeout in seconds
    timeoutSeconds: 10800

ingress:
  # -- Enable Ingress
  enabled: false
  # -- Ingress Class Name
  className: ""
  # -- Ingress Annotations
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  # -- TLS configuration
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# -- The command to pass at runtime
command: []

# -- The arguments to pass at runtime
args: []

## - Environment variables
envVars: {}
# - name: FOO
#   value: FOO
# - name: BAR
#   valueFrom:
#     secretKeyRef:
#       name: mySecret
#       key: bar

# -- The Resources
resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- Live and Readiness Probes
livenessProbe:
  httpGet:
    path: /_/health
    port: http
readinessProbe:
  httpGet:
    path: /_/health
    port: http

autoscaling:
  # -- Whether to enable autoscaling
  enabled: false
  # -- The minimum number of pods
  minReplicas: 1
  # -- The maximum number of pods
  maxReplicas: 100
  # -- The metrics to use for autoscaling
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
  # -- HPA behavior configuration
  behavior:
    # -- Scale down behavior configuration
    scaleDown: {}
      # stabilizationWindowSeconds: 300
      # policies:
      # - type: Percent
      #   value: 20
      #   periodSeconds: 60
    # -- Scale up behavior configuration
    scaleUp: {}
      # stabilizationWindowSeconds: 0
      # policies:
      # - type: Percent
      #   value: 100
      #   periodSeconds: 15

# -- Vertical Pod Autoscaler configuration
#
# Note: VPA requires the VPA controller + CRDs installed in the cluster.
vpa:
  # -- Whether to enable VPA
  enabled: false
  # -- Optional labels for the VPA object
  labels: {}
  # -- Optional annotations for the VPA object
  annotations: {}
  # -- Update policy configuration
  # Typical modes: Off | Initial | Recreate | Auto
  updatePolicy:
    updateMode: Off
  # -- Resource policy configuration
  # Example:
  # resourcePolicy:
  #   containerPolicies:
  #     - containerName: "*"
  #       controlledResources: ["cpu", "memory"]
  resourcePolicy: {}
  # -- Optional recommenders list
  recommenders: []

# -- Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# -- Persistence configuration for the main workload (Deployment/StatefulSet).
#
# When enabled:
# - Deployment: creates a PVC (unless existingClaim is set) and mounts it.
# - StatefulSet: uses volumeClaimTemplates (unless existingClaim is set).
persistence:
  # -- Enable persistence (PVC/volumeClaimTemplates) for the main workload.
  enabled: false
  # -- The volume name (also the volumeClaimTemplates name for StatefulSets).
  name: app-data
  # -- Path where the volume should be mounted.
  mountPath: /data/app
  # -- Optional subPath within the volume.
  subPath: ""
  # -- Use an existing PVC instead of creating one / using volumeClaimTemplates.
  existingClaim: ""
  # -- (Deployment only) PVC name to create + mount.
  # When empty, defaults to: <release>-<chart>-data (i.e. <fullname>-data).
  claimName: ""
  # -- Access modes for the PVC/volumeClaimTemplates.
  accessModes:
    - ReadWriteMany
  # -- Requested storage size.
  size: 1Gi
  # -- StorageClass name to use (empty means use the cluster default).
  storageClassName: do-block-storage

# -- Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

# -- Node selector labels
nodeSelector: {}

# -- Tolerations for pod assignment
tolerations: []

# -- Affinity for pod assignment
affinity: {}

# -- Lifecycle hooks
lifecycle:
  preStop:
    exec:
      command:
      - sh
      - -c
      - sleep 15 && kill -3 1

# -- ServiceMonitor configuration for Prometheus monitoring
serviceMonitor:
  # -- Whether to enable ServiceMonitor
  enabled: false
  # -- ServiceMonitor annotations
  annotations: {}
  # -- ServiceMonitor endpoints configuration
  endpoints: []
  # - port: http
  #   path: /metrics
  #   interval: 30s
  #   scheme: http

# -- Secrets configuration
secrets: []
# - name: my-secret
#   items:
#   - key: username
#     value: myuser
#   - key: password
#     value: mypass

# -- ConfigMap configuration
configmap:
  # -- Whether to create a ConfigMap
  enabled: false
  # -- ConfigMap name override (defaults to <fullname>)
  name: ""
  # -- Additional labels for the ConfigMap
  labels: {}
  # -- Additional annotations for the ConfigMap
  annotations: {}
  # -- ConfigMap data
  data: {}
  # -- ConfigMap binaryData
  binaryData: {}

# -- Extra containers to run alongside the main container (sidecar containers)
extraContainers: []
# - name: sidecar-container
#   image: busybox:latest
#   imagePullPolicy: IfNotPresent
#   command: ["sh", "-c", "while true; do echo 'sidecar running'; sleep 60; done"]
#   env:
#   - name: SIDECAR_ENV
#     value: "test"
#   resources:
#     requests:
#       memory: "64Mi"
#       cpu: "250m"
#     limits:
#       memory: "128Mi"
#       cpu: "500m"
#   ports:
#   - containerPort: 8080
#     protocol: TCP
#   volumeMounts:
#   - name: shared-data
#     mountPath: /shared
#   securityContext:
#     runAsNonRoot: true
#     runAsUser: 1000

# -- Extra Kubernetes objects to deploy
extraObjects: []
# - apiVersion: v1
#   kind: ConfigMap
#   metadata:
#     name: my-configmap
#   data:
#     config.yaml: |
#       key: value
# - apiVersion: v1
#   kind: Secret
#   metadata:
#     name: my-extra-secret
#   data:
#     key: dmFsdWU=

job:
  # -- Enable creation of a Kubernetes Job
  enabled: false
  # -- Job annotations
  annotations: {}
  # -- Job labels
  labels: {}
  # -- Number of retries before marking as failed
  backoffLimit: 6
  # -- Desired number of successfully finished pods
  completions: null
  # -- Max number of pods running in parallel
  parallelism: null
  # -- Optional overall deadline for the Job (seconds)
  activeDeadlineSeconds: null
  # -- Optional TTL to clean up finished Jobs (seconds)
  ttlSecondsAfterFinished: null
  # -- Pod restart policy for the Job pod
  restartPolicy: OnFailure
  # -- Additional annotations for the Job pod template (defaults to podAnnotations)
  podAnnotations: {}
  # -- Additional labels for the Job pod template (defaults to podLabels)
  podLabels: {}
  # -- Additional volumes for the Job pod template (merged with top-level volumes)
  volumes: []
  # - name: workdir
  #   emptyDir: {}
  # - name: data
  #   persistentVolumeClaim:
  #     claimName: my-existing-pvc
  # -- Additional volumeMounts for the Job pod template (merged with top-level volumeMounts)
  volumeMounts: []
  # - name: workdir
  #   mountPath: /work
  # - name: data
  #   mountPath: /data

cronjob:
  # -- Enable creation of a Kubernetes CronJob
  enabled: false
  # -- CronJob annotations
  annotations: {}
  # -- CronJob labels
  labels: {}
  # -- Cron schedule in standard Cron format
  schedule: "0 * * * *"
  # -- Optional timezone for the schedule (Kubernetes 1.27+)
  timeZone: ""
  # -- How to treat concurrent executions (Allow|Forbid|Replace)
  concurrencyPolicy: Forbid
  # -- Optional deadline in seconds for starting the job if it misses scheduled time
  startingDeadlineSeconds: null
  # -- Whether to suspend subsequent executions
  suspend: false
  # -- How many completed jobs should be kept
  successfulJobsHistoryLimit: 3
  # -- How many failed jobs should be kept
  failedJobsHistoryLimit: 1

  job:
    # -- Number of retries before marking as failed
    backoffLimit: 6
    # -- Desired number of successfully finished pods
    completions: null
    # -- Max number of pods running in parallel
    parallelism: null
    # -- Optional overall deadline for the Job (seconds)
    activeDeadlineSeconds: null
    # -- Optional TTL to clean up finished Jobs (seconds)
    ttlSecondsAfterFinished: null
    # -- Pod restart policy for the CronJob job pod
    restartPolicy: OnFailure
    # -- Additional annotations for the CronJob job pod template (defaults to podAnnotations)
    podAnnotations: {}
    # -- Additional labels for the CronJob job pod template (defaults to podLabels)
    podLabels: {}
    # -- Additional volumes for the CronJob job pod template (merged with top-level volumes)
    volumes: []
    # - name: workdir
    #   emptyDir: {}
    # - name: data
    #   persistentVolumeClaim:
    #     claimName: my-existing-pvc
    # -- Additional volumeMounts for the CronJob job pod template (merged with top-level volumeMounts)
    volumeMounts: []
    # - name: workdir
    #   mountPath: /work
    # - name: data
    #   mountPath: /data
